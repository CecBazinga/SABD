Script e report per la creazione dell'ambiente di lavoro (Ubuntu 20.04)

 - Installare IntelliJ IDEA con JDK 1.8

 $ sudo apt-get update
 $ sudo apt install vim
 $ sudo apt install git
 
 - Installare Containerd, Docker CE CLI e Docker CE (Engine) da: https://download.docker.com/linux/ubuntu/dists/focal/pool/stable/amd64/
   (Per installarli è necessario fare $ sudo dpkg -i path/to/package nell'ordine specificato sopra.)
 
 - [OPZIONALE] $ sudo docker run hello-world per testare docker
 
 


 ****[SETUP DI HADOOP]****
 
 	- Scaricare gli script di Fabiana Rossi (Presenti nel sito della Cardellini alla lezione di Hadoop)
 	
 	- E' stato fatto il cambio versione da Hadoop 3.1.4 a 3.2.2
 	
 	- Porsi nella cartella di src ed eseguire il comando $ docker build -t hadoop3-worker . e docker build -t hadoop3-master . nelle rispettive cartelle
 	 
 	- Porsi sulla cartella scripts ed eseguire start-docker.sh (si può usare anche il Dockerfile)
 	
 	- Eseguire sulla macchina master (quella che si apre dopo aver eseguito il .sh) il comando $ hdfs namenode -format per formattare ed inizializzare il file system
 	
 	- Fare lo startup dei vari namenode con il comando $ $HADOOP_HOME/sbin/start-dfs.sh
 	
 	- [OPZIONALE] Fare il check del corretto funzionamento con $ hdfs dfsadmin -report, oppure collegandoci a http://localhost:9870/dfshealth.html
 	
 	- Eseguire stop-docker.sh per terminare i container
  
 
 
 
 
 
 


[NOTE PER LA RELAZIONE]

- Abbiamo usato build iun locale invece che su amazon per familiarizzare con l'instansiazione della roba manualmente (AWS fa tutto in automatico)

- Usiamo Parquet perchè è column-based ed è ottimale per analytic reads

- L'applicazione client dovrà girare all'interno dell'ambiente docker per permettere l'accesso alla sottorete (con tutte le porte e gli IP del cluster hadoop)

- I Namenode di HFDS e Workernode di YARN si trovano sulla stessa macchina come il Resource Manager (YARN) e Masternode (HDFS)?
